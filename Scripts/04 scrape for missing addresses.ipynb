{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import sys\n",
    "import re\n",
    "import webbrowser\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/4028904/how-to-get-the-home-directory-in-python\n",
    "from os.path import expanduser\n",
    "from os import listdir\n",
    "executable_path = expanduser(\"~\") + \"/chromedriver\"\n",
    "\n",
    "if 'chromedriver.exe' not in listdir(expanduser(\"~\")):\n",
    "    print('chomedriver.exe not found in the home directory! Refer to Selenium docs.')\n",
    "    sys.exit()\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/4028904/how-to-get-the-home-directory-in-python\n",
    "from os.path import expanduser\n",
    "from os import listdir\n",
    "executable_path = expanduser(\"~\") + \"/chromedriver\"\n",
    "\n",
    "if 'chromedriver.exe' not in listdir(expanduser(\"~\")):\n",
    "    print('chomedriver.exe not found in the home directory! Refer to Selenium docs.')\n",
    "    sys.exit()\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opportunities = pd.read_csv('opportunities.csv')\n",
    "# use this if restarting scraper\n",
    "opportunities = pd.read_csv('opportunities_scraped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opportunities['scraped_address']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities[opportunities.scraped_address != 'not found'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities.head(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\n",
    "    executable_path=\"/Users/rajchakrabarty/Downloads/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export to csv\n",
    "opportunities.to_csv('opportunities_scraped.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    driver = webdriver.Chrome(\n",
    "        executable_path=\"/Users/rajchakrabarty/Downloads/chromedriver\")\n",
    "    counter = 0\n",
    "    for i, row in opportunities[(opportunities['scraped_address'].isnull() == True)].iterrows():\n",
    "        search_term = ''\n",
    "        url = ''\n",
    "        address = ''\n",
    "        search_term = row['Opportunity Name'].replace(' ', '+')+'+address'\n",
    "        url = 'https://www.google.com/search?\\&q='+search_term\n",
    "        driver.get(url)\n",
    "        search_bar = driver.find_element_by_id('lst-ib')\n",
    "        search_bar.clear()\n",
    "        search_bar.send_keys(search_term)\n",
    "        response = driver.page_source\n",
    "        html = BeautifulSoup(response, 'lxml')\n",
    "        span = html.find('span', {'class': 'LrzXr'})\n",
    "        #print (i, search_term)\n",
    "        try:\n",
    "            address = span.text\n",
    "        except:\n",
    "            address = 'not found'\n",
    "        # print(address)\n",
    "        opportunities.loc[opportunities['Opportunity ID'] ==\n",
    "                          row['Opportunity ID'], 'scraped_address'] = address\n",
    "        counter += 1\n",
    "        if counter % 20 == 0:\n",
    "            print(i, search_term)\n",
    "            print(address)\n",
    "            # sleep(10)\n",
    "\n",
    "\n",
    "print('start')\n",
    "keep_going = True\n",
    "while keep_going:\n",
    "    try:\n",
    "        scrape()\n",
    "        keep_going = False\n",
    "    except:\n",
    "        opportunities.to_csv('opportunities_scraped.csv', index_label=False)\n",
    "\n",
    "opportunities.to_csv('opportunities_scraped.csv', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
